{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Denoising\n",
    "\n",
    "Image, especially natural images, are very susceptible to noise. Noise can be caused by countless causes, such as lighting conditions, sensor limitations, or transmission errors.\n",
    "\n",
    "With the help of machine learning, autoencoders are one of the most popular methods to denoise images. In this project, I aim to build an pseudo-autoencoder using statistical methods we learned for image denoising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder\n",
    "\n",
    "Autoencoder is a type of neural network that learns to compress data (encoding) and then reconstruct the data back (decoding). \n",
    "\n",
    "The bottleneck layer in between the encoding and decoding layers is where the data is compressed. The dimensionality of the bottleneck layer is usually lower than the input and output layers, forcing the network to learn the most important features of the data and discard the noise. Then, this compressed latent representation is used to reconstruct the original data.\n",
    "\n",
    "## Pseudo-Autoencoder\n",
    "\n",
    "Now, divide the autoencoder architecture into two parts, the encoder and the decoder. The encoder is a function that maps the input data to the compressed latent representation. The decoder is a function that maps the compressed latent representation back to the original data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANSAC algorithm\n",
    "\n",
    "RANSAC (Random Sample Consensus) is an iterative algorithm used to estimate the parameters of a mathematical model from a set of observed data. The algorithm selects a random subset of the data, fits the model to the subset, and then tests the model on the remaining data. This process helps to identify the outliers in the data, which does not fit to the trend of the data. \n",
    "\n",
    "A detailed steps of RANSAC algorithm is as follows:\n",
    "1. Select a random subset of data points to be *hypothetical inliers*\n",
    "2. Fit the model to the set of *hypothetical inliers*.\n",
    "3. Test all other data points against the fitted model. The points that fit well to the model are considered as *inliers*, and called the *consensus set*.\n",
    "4. Refit the model using all *inliers*.\n",
    "5. Estimate the error of the fitted model.\n",
    "6. Repeat the steps until the model fits the data well enough, or if a set number of iterations have been reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
